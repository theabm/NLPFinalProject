\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Problem Statement }{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Data Description }{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The top 10 most frequent categories of books. "Fiction", "history", and "religion" figure among the top 3.}}{2}{}\protected@file@percent }
\newlabel{fig:categories}{{1}{2}}
\citation{firstbib}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The distribution of scores shows that classes are unbalanced and the majority is composed of 5 star reviews.}}{3}{}\protected@file@percent }
\newlabel{fig:scores}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Assessment and Performance Indexes }{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Topic Modeling }{3}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The word-cloud of the most frequent terms in the corpus of book summaries. Terms such as "work", "world", "life", "history", "time", "love", "family" indicate the themes being discussed.}}{4}{}\protected@file@percent }
\newlabel{fig:ldaword}{{3}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces UMass and CV scores with varying number of topics. The maximum occurs at $K=10$ which indicate the optimal number of topics.}}{4}{}\protected@file@percent }
\newlabel{fig:umasscv}{{4}{4}}
\citation{secondbib}
\citation{thirdbib}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Frequency of topics per year since 2012. The overall trend is downwards, however, 2 years ago, \texttt  {fictional romance} increased.}}{6}{}\protected@file@percent }
\newlabel{fig:topicyears}{{5}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Sentiment Analysis }{6}{}\protected@file@percent }
\citation{fourthbib}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Negative reviews word cloud (a) and positive reviews word cloud (b) reveal the words associated to negative and positive emotions respectively.}}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{7}{}\protected@file@percent }
\newlabel{fig:sentimentword}{{6}{7}}
\citation{fifthbib}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Distribution of positive and negative class.}}{8}{}\protected@file@percent }
\newlabel{fig:posvsneg}{{7}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Metrics for RoBERTa after fine-tuning on $60,000$ reviews. After the first 2 epochs, the model is clearly over-fitting as can be seen by the decrease in training loss and increase in validation loss.}}{8}{}\protected@file@percent }
\newlabel{fig:robertaft}{{8}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Comparison between baseline, RoBERTa, and RoBERTa fine-tuned. The latter model has the best overall performance.}}{9}{}\protected@file@percent }
\newlabel{fig:perfcomp}{{9}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results and Discussion }{10}{}\protected@file@percent }
\bibcite{firstbib}{1}
\bibcite{secondbib}{2}
\bibcite{thirdbib}{3}
\bibcite{fourthbib}{4}
\bibcite{fifthbib}{5}
\gdef \@abspage@last{11}
